rule annovar:
    input:
        "table/{sample}.csv"
    output:
        anno = "table/{sample}.anno.csv",
        tmp = temp("table/{sample}.annotmp.csv")
    log:
        "logs/annovar/{sample}.log"
    threads:
        8
    resources:
        time="00:30:00",
        mem="20G",
        mem_mb="20G",
    params:
        annovar = config['tools']['annovar'],
        anno = get_anno_params,
        sd = config["general"]['snakedir'],
        anno_info = f"scripts/shell/sed.cmd"
    shell:
        r"""
        tail -n +2 {input} > {output.tmp} && \
        {params.annovar}/table_annovar.pl {output.tmp} {params.anno} -thread {threads} && \
        sed --file={params.sd}/{params.anno_info} {output.tmp}.hg38_multianno.txt > {output.anno} && \
        rm {output.tmp}.hg38_multianno.txt
        """

if config["general"]["control"]:
    rule ebfilter:
        input:
            sample = lambda wildcards: input_bam[wildcards.sample],
            vcf = "vardict/{sample}.vcf"
        output:
            vcf = "vardict/{sample}_EB.vcf",
            txt = "vardict/{sample}_EB.txt"
        log:
            "logs/EBFilter/{sample}.log"
        threads:
            4
        resources:
            time=get_time_3_1,
            mem=get_mem_30_10,
            mem_mb=get_mem_30_10
        conda:
            "../env/EBFilter-env.yml"
        params:
            normals = config['edit']['normals']
        shell:
            r"""
            EBFilter -f vcf -t {threads} {input.vcf} {input.sample} {params.normals} {output.vcf}
            bcftools query -f '[%EB]\n' {output.vcf} > {output.txt} 2>/dev/null
            """
else:
    rule fake_ebfilter:
        input:
            vcf = "vardict/{sample}.vcf"
        output:
            txt = "vardict/{sample}_EB.txt"
        log:
            "logs/EBFilter/{sample}.log"
        threads:
            1
        resources:
            time=get_time_1_1,
            mem_mb="10G"
        run:
           with open(input.vcf, "r") as input_file:
              vcf_lines = sum(1 for line in input_file if not line.startswith("#"))
           
           with open(output.txt, "w") as output_file:
              output_file.write("\n".join(["NaN"] * vcf_lines))

rule add_ebfilter:
    input:
        anno = "table/{sample}.anno.csv",
        ebfilter = "vardict/{sample}_EB.txt"
    output:
        "table/{sample}.edit.csv"
    threads:
        1
    resources:
        time="00:30:00"
    params:
        wd = config["general"]["work_dir_variantcalling"],
        sd = config["general"]['snakedir'],
        rs = f"scripts/AddParameters.R",
        candidate = config['edit']['candidate_list'],
        driver = config['edit']['driver_list'],
        CHIP = config['edit']['CHIP_list']
    shell:
        r"""
        Rscript {params.sd}/{params.rs} {params.wd}/{input.anno} {params.wd}/{output} {params.candidate} {params.driver} {params.CHIP} {params.wd}/{input.ebfilter}
        """

rule primer3:
    input: "table/{sample}.edit.csv"
    output: "table/{sample}.edit.primer.csv"
    conda:
        "../env/primer3-env.yml"
    threads: 1
    resources:
        time="00:30:00",
        mem_mb=get_mem_3_1
    params:
        genome_split = config["primer3"]["split"]
    script:
        "../scripts/primer3.py"


rule detect_HDR:
    input:
        filter_file = "table/{sample}.edit.csv",
        bam = "filterbam/{sample}.bam",
        index = "filterbam/{sample}.bai",
        pileup = "pileup/{sample}.pileup"
    output:
        HDR = "table/{sample}.edit.HDR.csv"
    conda:
        f"../env/HDR-env.yml"
    threads: 1
    resources:
        time=get_time_3_1,
        mem=get_mem_40_10,
        mem_mb=get_mem_40_10
    params:
        min_sim = config['HDR']['min_similarity'],
        min_q = config['HDR']['min_q'],
        min_HDR_count = config['HDR']['min_HDR_count']
    script:
        "../scripts/HDR.py"


rule combine_annotations:
    input:
        anno_edit = "table/{sample}.edit.csv",
        primer = "table/{sample}.edit.primer.csv",
        hdr = "table/{sample}.edit.HDR.csv"
    output: 
        "filter/{sample}.edit.csv"
    params: 
        wd = config["general"]["work_dir_variantcalling"],
        sd = config["general"]['snakedir'],
        rs = f"scripts/CombineAnno.R"
    threads: 1
    resources:
        time="00:30:00"
    shell:
        r"""
        Rscript {params.sd}/{params.rs} {params.wd}/{input.anno_edit} {params.wd}/{input.primer} {params.wd}/{input.hdr} {params.wd}/{output}
        """

rule combine_samples:
    input:
        expand("filter/{sample}.edit.csv", sample = samples)
    output: 
        "filter/variantcalls.csv"
    params: 
        wd = config["general"]["work_dir_variantcalling"],
        sd = config["general"]['snakedir'],
        rs = f"scripts/MergeCalls.R"
    threads: 1
    resources:
        time="00:20:00",
        mem_mb=get_mem_30_10
    shell:
        r"""
        Rscript {params.sd}/{params.rs} {params.wd}/filter {params.wd}/{output}
        """

